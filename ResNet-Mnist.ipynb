{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet on Cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import cPickle\n",
    "import sys\n",
    "import os\n",
    "import gzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def log(log_file_path, string):\n",
    "    '''\n",
    "    Write one line of log into screen and file.\n",
    "        log_file_path: Path of log file.\n",
    "        string:        String to write in log file.\n",
    "    '''\n",
    "    with open(log_file_path, 'a+') as f:\n",
    "        f.write(string + '\\n')\n",
    "        f.flush()\n",
    "    print(string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mnist_dir = '/scratch/f1fan/ResNet/data/'\n",
    "train_image_f = 'train-images-idx3-ubyte.gz'\n",
    "train_label_f = 'train-labels-idx1-ubyte.gz'\n",
    "test_image_f = 't10k-images-idx3-ubyte.gz'\n",
    "test_label_f = 't10k-labels-idx1-ubyte.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _read32(bytestream):\n",
    "    dt = np.dtype(np.uint32).newbyteorder('>')\n",
    "    return np.frombuffer(bytestream.read(4), dtype=dt)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def load_train_data():\n",
    "    img_f = os.path.join(mnist_dir, train_image_f)\n",
    "    lbl_f = os.path.join(mnist_dir, train_label_f)\n",
    "    \n",
    "    with gzip.open(img_f) as img_bytestream, gzip.open(lbl_f) as lbl_bytestream:\n",
    "        # Check magic number\n",
    "        magic_img, magic_lbl = _read32(img_bytestream), _read32(lbl_bytestream)\n",
    "        if magic_img != 2051 or magic_lbl != 2049:\n",
    "            raise ValueError('Invalid magic number')\n",
    "        \n",
    "        # Read shape\n",
    "        image_cnt, label_cnt = _read32(img_bytestream), _read32(lbl_bytestream)\n",
    "        rows = _read32(img_bytestream)\n",
    "        cols = _read32(img_bytestream)\n",
    "        \n",
    "        # Read label\n",
    "        label_buf = lbl_bytestream.read(label_cnt)\n",
    "        labels = np.frombuffer(label_buf, dtype=np.uint8)\n",
    "        \n",
    "        # Read image\n",
    "        image_buf = img_bytestream.read(rows * cols * image_cnt)\n",
    "        images = np.frombuffer(image_buf, dtype=np.uint8)\n",
    "        images = images.reshape(image_cnt, rows, cols, 1)\n",
    "        \n",
    "        return images, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def load_test_data():\n",
    "    img_f = os.path.join(mnist_dir, test_image_f)\n",
    "    lbl_f = os.path.join(mnist_dir, test_label_f)\n",
    "    \n",
    "    with gzip.open(img_f) as img_bytestream, gzip.open(lbl_f) as lbl_bytestream:\n",
    "        # Check magic number\n",
    "        magic_img, magic_lbl = _read32(img_bytestream), _read32(lbl_bytestream)\n",
    "        if magic_img != 2051 or magic_lbl != 2049:\n",
    "            raise ValueError('Invalid magic number')\n",
    "        \n",
    "        # Read shape\n",
    "        image_cnt, label_cnt = _read32(img_bytestream), _read32(lbl_bytestream)\n",
    "        rows = _read32(img_bytestream)\n",
    "        cols = _read32(img_bytestream)\n",
    "        \n",
    "        # Read label\n",
    "        label_buf = lbl_bytestream.read(label_cnt)\n",
    "        labels = np.frombuffer(label_buf, dtype=np.uint8)\n",
    "        \n",
    "        # Read image\n",
    "        image_buf = img_bytestream.read(rows * cols * image_cnt)\n",
    "        images = np.frombuffer(image_buf, dtype=np.uint8)\n",
    "        images = images.reshape(image_cnt, rows, cols, 1)\n",
    "        \n",
    "        return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_per_pixel_mean(train_images, test_images):\n",
    "    images = np.concatenate((train_images, test_images), axis=0)\n",
    "    return np.mean(images, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training stage 1: Load training and testing images...\n"
     ]
    }
   ],
   "source": [
    "log_file_path = os.path.join('/scratch/f1fan/ResNet', \"log.txt\")  \n",
    "log(log_file_path,\n",
    "    \"Training stage 1: Load training and testing images...\")\n",
    "train_images, train_labels = load_train_data()\n",
    "test_images, test_labels = load_test_data()\n",
    "\n",
    "#train_images = train_images - pp_mean\n",
    "#train_images = train_images / 128.0\n",
    "#test_images = test_images - pp_mean\n",
    "#test_images = test_images / 128.0\n",
    "\n",
    "train_images = 1.0 * train_images / 255 * 2.0 - 1.0\n",
    "test_images = 1.0 * test_images / 255 * 2.0 - 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_units = 5\n",
    "epoch = 40\n",
    "batch_size = 100\n",
    "iteration_per_epoch = train_images.shape[0] // batch_size\n",
    "learning_rate = 0.1\n",
    "decay_rate = 0.0002  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layer functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def conv2d(input_layer, output_channels, filter_size, strides, scope):    \n",
    "    with tf.variable_scope(scope):\n",
    "        # Variable for filter.\n",
    "        in_channels = input_layer.get_shape().as_list()[-1]\n",
    "    \n",
    "        conv_filter = tf.get_variable(\n",
    "            name = 'filter', \n",
    "            shape = [filter_size, filter_size, in_channels, output_channels],\n",
    "            initializer = tf.truncated_normal_initializer(stddev = 0.02),\n",
    "            regularizer = tf.contrib.layers.l2_regularizer(scale = 0.0002)\n",
    "        )\n",
    "        # Do convolution.\n",
    "        conv = tf.nn.conv2d(input_layer, \n",
    "                            conv_filter, \n",
    "                            strides = strides, \n",
    "                            padding = 'SAME')\n",
    "        # Variable for bias.\n",
    "        bias = tf.get_variable(name = 'bias', \n",
    "                               shape = [output_channels], \n",
    "                               initializer = tf.constant_initializer(0.0))\n",
    "        # Add bias.\n",
    "        conv = tf.reshape(tf.nn.bias_add(conv, bias), conv.get_shape())\n",
    "\n",
    "        return conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def lrelu(input_layer, leak=0.2):\n",
    "    # Do leaky ReLU and return.\n",
    "    #return tf.maximum(input_layer, leak * input_layer)\n",
    "    return tf.nn.relu(input_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def fully_connected(input_layer, output_dim, scope):\n",
    "    shape = input_layer.get_shape().as_list()\n",
    "    batch_size, input_dim = shape\n",
    "    \n",
    "    with tf.variable_scope(scope):\n",
    "        # Variable of weight.\n",
    "        weight = tf.get_variable(\n",
    "            name = 'weight', \n",
    "            shape = [input_dim, output_dim], \n",
    "            dtype = tf.float32,\n",
    "            initializer = tf.random_normal_initializer(stddev = 0.02),\n",
    "            regularizer = tf.contrib.layers.l2_regularizer(0.0002)\n",
    "        )\n",
    "        \n",
    "        # Variable of bias.\n",
    "        bias = tf.get_variable(name = \"bias\", \n",
    "                               shape = [output_dim],\n",
    "                               initializer = tf.constant_initializer(0.0))\n",
    "\n",
    "        # Do multiplication and return.\n",
    "        return tf.matmul(input_layer, weight) + bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def batch_norm(input_layer, is_training, scope, reuse):\n",
    "    return tf.contrib.layers.batch_norm(input_layer,\n",
    "                                        decay = 0.9, \n",
    "                                        updates_collections = None,\n",
    "                                        epsilon = 1e-5,\n",
    "                                        scale = True,\n",
    "                                        is_training = is_training,\n",
    "                                        reuse = reuse,\n",
    "                                        scope = scope)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def avg_pool(input_layer, strides, scope):\n",
    "    with tf.variable_scope(scope):\n",
    "        return tf.nn.avg_pool(input_layer, ksize=strides, strides=strides, padding='VALID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def w_decay():\n",
    "    cost = []\n",
    "    for var in tf.trainable_variables():\n",
    "        if var.op.name.find(r'filter') > 0:\n",
    "            cost.append(tf.nn.l2_loss(var))\n",
    "    return tf.mul(decay_rate, tf.add_n(cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def residual(input_layer, increase_dim, first, scope):\n",
    "    in_channels = input_layer.get_shape().as_list()[-1]\n",
    "\n",
    "    if increase_dim:\n",
    "        out_channels = in_channels * 2\n",
    "        strides = [1, 2, 2, 1]\n",
    "    else:\n",
    "        out_channels = in_channels\n",
    "        strides = [1, 1, 1, 1]\n",
    "\n",
    "    with tf.variable_scope(scope):\n",
    "        h0 = input_layer if first else lrelu(batch_norm(input_layer, is_training=True, scope='h0_bn', reuse=False))\n",
    "        \n",
    "        h1_conv = conv2d(h0, out_channels, filter_size=3, strides=strides, scope='h1_conv')\n",
    "        h1 = lrelu(batch_norm(h1_conv, is_training=True, scope='h1_bn', reuse=False))\n",
    "        \n",
    "        h2_conv = conv2d(h1, out_channels, filter_size=3, strides=[1, 1, 1, 1], scope='h2_conv')\n",
    "        \n",
    "        if increase_dim:\n",
    "            l = avg_pool(input_layer, strides=[1, 2, 2, 1], scope='l_pool')\n",
    "            l = tf.pad(l, [[0, 0], [0, 0], \n",
    "                           [0, 0], [in_channels // 2, in_channels // 2]])\n",
    "        else:\n",
    "            l = input_layer\n",
    "\n",
    "        h2 = tf.add(h2_conv, l)\n",
    "\n",
    "        return h2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def resnet(images, num_units):\n",
    "    with tf.variable_scope('ResNet', reuse=False):\n",
    "        init_dim = 16\n",
    "        batch_size = images.get_shape().as_list()[0]\n",
    "        \n",
    "        r0_conv = conv2d(images, init_dim, filter_size=3, strides=[1, 1, 1, 1], scope='r0_conv')\n",
    "        r0 = lrelu(batch_norm(r0_conv, is_training=True, scope='r0_bn', reuse=False))\n",
    "        \n",
    "        r1_res = residual(r0, increase_dim=False, first=True, scope='res1.0')\n",
    "        for k in xrange(1, num_units):\n",
    "            r1_res = residual(r1_res, increase_dim=False, first=False, scope='res1.{0}'.format(k))\n",
    "\n",
    "        r2_res = residual(r1_res, increase_dim=True, first=False, scope='res2.0')\n",
    "        for k in xrange(1, num_units):\n",
    "            r2_res = residual(r2_res, increase_dim=False, first=False, scope='res2.{0}'.format(k))\n",
    "\n",
    "        r3_res = residual(r2_res, increase_dim=True, first=False, scope='res3.0')\n",
    "        for k in xrange(1, num_units):\n",
    "            r3_res = residual(r3_res, increase_dim=False, first=False, scope='res3.{0}'.format(k))\n",
    "\n",
    "        r4 = lrelu(batch_norm(r3_res, is_training=True, scope='r4_bn', reuse=False))\n",
    "        \n",
    "        axis = [1, 2]\n",
    "        r5 = tf.reduce_mean(r4, axis, name='global_pool')\n",
    "\n",
    "        fc = fully_connected(tf.reshape(r5, [batch_size, -1]), output_dim=10, scope='fully_connected')\n",
    "        return tf.nn.softmax(fc), fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def build_network(batch_shape):\n",
    "    # Get shape of single batch\n",
    "    [batch_size, height, width, channels] = batch_shape\n",
    "    \n",
    "    # Placeholders\n",
    "    images = tf.placeholder(dtype=tf.float32,\n",
    "                            shape=batch_shape,\n",
    "                            name='images')\n",
    "    labels = tf.placeholder(dtype=tf.int32,\n",
    "                            shape=[batch_size,],\n",
    "                            name='labels')\n",
    "    # Calculate losses\n",
    "    probability, logits = resnet(images, num_units)\n",
    "    loss = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits,\n",
    "                                                   labels=labels)\n",
    "    loss = tf.reduce_mean(loss)\n",
    "    loss += w_decay()\n",
    "    \n",
    "    prediction = tf.equal(tf.cast(tf.argmax(probability, axis=1), tf.int32), labels)\n",
    "    accuracy = tf.reduce_mean(tf.cast(prediction, tf.float32))\n",
    "    \n",
    "    var = [x for x in tf.trainable_variables() if 'ResNet' in x.name]\n",
    "    return [loss, var, accuracy, images, labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_optimizers(loss, var):\n",
    "    with tf.variable_scope('optimizer'):\n",
    "        global_step = tf.Variable(initial_value = 0, trainable = False)\n",
    "        global_step_op = global_step.assign_add(1)\n",
    "        boundaries = [2400, 4000, 8000]\n",
    "        values = [0.1, 0.01, 0.001, 0.0002]\n",
    "        lr = tf.train.piecewise_constant(global_step, boundaries, values)\n",
    "        opt = tf.train.MomentumOptimizer(learning_rate=lr,\n",
    "                                         momentum=0.9)\n",
    "        optimizer = opt.minimize(loss=loss,\n",
    "                                 var_list=var)\n",
    "        return optimizer, global_step_op, global_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train(sess):\n",
    "    log(log_file_path,\n",
    "        \"Training stage 2: Build network and initialize...\")\n",
    "    # Build network\n",
    "    batch_shape = [batch_size, 28, 28, 1]\n",
    "    r_loss, r_var, r_accuracy, images, labels = build_network(batch_shape)\n",
    "    r_opt, global_step_op, global_step = get_optimizers(r_loss, r_var)\n",
    "    \n",
    "    # Show a list of global variables.\n",
    "    global_variables = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope='')\n",
    "    log(log_file_path, 'Global variables:')\n",
    "    for i, var in enumerate(global_variables):\n",
    "        log(log_file_path, \"{0} {1}\".format(i, var.name))\n",
    "        \n",
    "    # Initialize all variables\n",
    "    all_initializer_op = tf.global_variables_initializer()\n",
    "    sess.run(all_initializer_op)\n",
    "    \n",
    "    log(log_file_path, \"Training stage 3: Epoch training...\")\n",
    "    for i in range(epoch):\n",
    "        '''\n",
    "        schedule_idx = 0\n",
    "        schedule_epoch, schedule_lr = learning_rate_schedule[schedule_idx]\n",
    "        if i == schedule_epoch:\n",
    "            learning_rate = schedule_lr\n",
    "            schedule_idx += 1\n",
    "            print 'learning rate changed! current learning rate: ', learning_rate\n",
    "        '''\n",
    "            \n",
    "        # Shuffle training set\n",
    "        shuffle = np.random.permutation(train_images.shape[0])\n",
    "        for j in range(iteration_per_epoch):\n",
    "            # Get current batch of image\n",
    "            batch_images = train_images[shuffle[j * batch_size : (j + 1) * batch_size]]\n",
    "            batch_labels = train_labels[shuffle[j * batch_size : (j + 1) * batch_size]]\n",
    "            \n",
    "            #aug_batch_images = tf.map_fn(augment_train_image, batch_images).eval(session=sess)\n",
    "            \n",
    "            sess.run(r_opt, feed_dict = {images: batch_images, labels:batch_labels})\n",
    "            batch_loss, batch_accuracy = sess.run([r_loss, r_accuracy], \n",
    "                                                  feed_dict = {images: batch_images, labels:batch_labels})\n",
    "            if j % 50 == 0:\n",
    "                log(log_file_path, \"Training epoch {0}, iteration {1}, global_step {2}, batch_loss {3}, batch_accuracy {4}\".format(\n",
    "                    i, j, sess.run(global_step), batch_loss, batch_accuracy))\n",
    "            sess.run(global_step_op)\n",
    "        \n",
    "        test_batch_count = test_images.shape[0] // batch_size\n",
    "        test_loss = 0.0\n",
    "        test_accuracy = 0.0\n",
    "        for k in range(test_batch_count):\n",
    "            # Get current batch of image\n",
    "            batch_images = test_images[k * batch_size : (k + 1) * batch_size]\n",
    "            batch_labels = test_labels[k * batch_size : (k + 1) * batch_size]\n",
    "            \n",
    "            #aug_batch_images = tf.map_fn(augment_test_image, batch_images).eval(session=sess)\n",
    "            \n",
    "            batch_loss, batch_accuracy = sess.run([r_loss, r_accuracy], \n",
    "                                                  feed_dict = {images: batch_images, labels:batch_labels})\n",
    "            test_loss += batch_loss\n",
    "            test_accuracy += batch_accuracy\n",
    "            \n",
    "        log(log_file_path, 'Testing epoch {0}, loss {1}, error {2}'.format(\n",
    "                i, test_loss / test_batch_count, 1.0 - (test_accuracy / test_batch_count)))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training stage 2: Build network and initialize...\n",
      "Global variables:\n",
      "0 ResNet/r0_conv/filter:0\n",
      "1 ResNet/r0_conv/bias:0\n",
      "2 ResNet/r0_bn/beta:0\n",
      "3 ResNet/r0_bn/gamma:0\n",
      "4 ResNet/r0_bn/moving_mean:0\n",
      "5 ResNet/r0_bn/moving_variance:0\n",
      "6 ResNet/res1.0/h1_conv/filter:0\n",
      "7 ResNet/res1.0/h1_conv/bias:0\n",
      "8 ResNet/res1.0/h1_bn/beta:0\n",
      "9 ResNet/res1.0/h1_bn/gamma:0\n",
      "10 ResNet/res1.0/h1_bn/moving_mean:0\n",
      "11 ResNet/res1.0/h1_bn/moving_variance:0\n",
      "12 ResNet/res1.0/h2_conv/filter:0\n",
      "13 ResNet/res1.0/h2_conv/bias:0\n",
      "14 ResNet/res1.1/h0_bn/beta:0\n",
      "15 ResNet/res1.1/h0_bn/gamma:0\n",
      "16 ResNet/res1.1/h0_bn/moving_mean:0\n",
      "17 ResNet/res1.1/h0_bn/moving_variance:0\n",
      "18 ResNet/res1.1/h1_conv/filter:0\n",
      "19 ResNet/res1.1/h1_conv/bias:0\n",
      "20 ResNet/res1.1/h1_bn/beta:0\n",
      "21 ResNet/res1.1/h1_bn/gamma:0\n",
      "22 ResNet/res1.1/h1_bn/moving_mean:0\n",
      "23 ResNet/res1.1/h1_bn/moving_variance:0\n",
      "24 ResNet/res1.1/h2_conv/filter:0\n",
      "25 ResNet/res1.1/h2_conv/bias:0\n",
      "26 ResNet/res1.2/h0_bn/beta:0\n",
      "27 ResNet/res1.2/h0_bn/gamma:0\n",
      "28 ResNet/res1.2/h0_bn/moving_mean:0\n",
      "29 ResNet/res1.2/h0_bn/moving_variance:0\n",
      "30 ResNet/res1.2/h1_conv/filter:0\n",
      "31 ResNet/res1.2/h1_conv/bias:0\n",
      "32 ResNet/res1.2/h1_bn/beta:0\n",
      "33 ResNet/res1.2/h1_bn/gamma:0\n",
      "34 ResNet/res1.2/h1_bn/moving_mean:0\n",
      "35 ResNet/res1.2/h1_bn/moving_variance:0\n",
      "36 ResNet/res1.2/h2_conv/filter:0\n",
      "37 ResNet/res1.2/h2_conv/bias:0\n",
      "38 ResNet/res1.3/h0_bn/beta:0\n",
      "39 ResNet/res1.3/h0_bn/gamma:0\n",
      "40 ResNet/res1.3/h0_bn/moving_mean:0\n",
      "41 ResNet/res1.3/h0_bn/moving_variance:0\n",
      "42 ResNet/res1.3/h1_conv/filter:0\n",
      "43 ResNet/res1.3/h1_conv/bias:0\n",
      "44 ResNet/res1.3/h1_bn/beta:0\n",
      "45 ResNet/res1.3/h1_bn/gamma:0\n",
      "46 ResNet/res1.3/h1_bn/moving_mean:0\n",
      "47 ResNet/res1.3/h1_bn/moving_variance:0\n",
      "48 ResNet/res1.3/h2_conv/filter:0\n",
      "49 ResNet/res1.3/h2_conv/bias:0\n",
      "50 ResNet/res1.4/h0_bn/beta:0\n",
      "51 ResNet/res1.4/h0_bn/gamma:0\n",
      "52 ResNet/res1.4/h0_bn/moving_mean:0\n",
      "53 ResNet/res1.4/h0_bn/moving_variance:0\n",
      "54 ResNet/res1.4/h1_conv/filter:0\n",
      "55 ResNet/res1.4/h1_conv/bias:0\n",
      "56 ResNet/res1.4/h1_bn/beta:0\n",
      "57 ResNet/res1.4/h1_bn/gamma:0\n",
      "58 ResNet/res1.4/h1_bn/moving_mean:0\n",
      "59 ResNet/res1.4/h1_bn/moving_variance:0\n",
      "60 ResNet/res1.4/h2_conv/filter:0\n",
      "61 ResNet/res1.4/h2_conv/bias:0\n",
      "62 ResNet/res2.0/h0_bn/beta:0\n",
      "63 ResNet/res2.0/h0_bn/gamma:0\n",
      "64 ResNet/res2.0/h0_bn/moving_mean:0\n",
      "65 ResNet/res2.0/h0_bn/moving_variance:0\n",
      "66 ResNet/res2.0/h1_conv/filter:0\n",
      "67 ResNet/res2.0/h1_conv/bias:0\n",
      "68 ResNet/res2.0/h1_bn/beta:0\n",
      "69 ResNet/res2.0/h1_bn/gamma:0\n",
      "70 ResNet/res2.0/h1_bn/moving_mean:0\n",
      "71 ResNet/res2.0/h1_bn/moving_variance:0\n",
      "72 ResNet/res2.0/h2_conv/filter:0\n",
      "73 ResNet/res2.0/h2_conv/bias:0\n",
      "74 ResNet/res2.1/h0_bn/beta:0\n",
      "75 ResNet/res2.1/h0_bn/gamma:0\n",
      "76 ResNet/res2.1/h0_bn/moving_mean:0\n",
      "77 ResNet/res2.1/h0_bn/moving_variance:0\n",
      "78 ResNet/res2.1/h1_conv/filter:0\n",
      "79 ResNet/res2.1/h1_conv/bias:0\n",
      "80 ResNet/res2.1/h1_bn/beta:0\n",
      "81 ResNet/res2.1/h1_bn/gamma:0\n",
      "82 ResNet/res2.1/h1_bn/moving_mean:0\n",
      "83 ResNet/res2.1/h1_bn/moving_variance:0\n",
      "84 ResNet/res2.1/h2_conv/filter:0\n",
      "85 ResNet/res2.1/h2_conv/bias:0\n",
      "86 ResNet/res2.2/h0_bn/beta:0\n",
      "87 ResNet/res2.2/h0_bn/gamma:0\n",
      "88 ResNet/res2.2/h0_bn/moving_mean:0\n",
      "89 ResNet/res2.2/h0_bn/moving_variance:0\n",
      "90 ResNet/res2.2/h1_conv/filter:0\n",
      "91 ResNet/res2.2/h1_conv/bias:0\n",
      "92 ResNet/res2.2/h1_bn/beta:0\n",
      "93 ResNet/res2.2/h1_bn/gamma:0\n",
      "94 ResNet/res2.2/h1_bn/moving_mean:0\n",
      "95 ResNet/res2.2/h1_bn/moving_variance:0\n",
      "96 ResNet/res2.2/h2_conv/filter:0\n",
      "97 ResNet/res2.2/h2_conv/bias:0\n",
      "98 ResNet/res2.3/h0_bn/beta:0\n",
      "99 ResNet/res2.3/h0_bn/gamma:0\n",
      "100 ResNet/res2.3/h0_bn/moving_mean:0\n",
      "101 ResNet/res2.3/h0_bn/moving_variance:0\n",
      "102 ResNet/res2.3/h1_conv/filter:0\n",
      "103 ResNet/res2.3/h1_conv/bias:0\n",
      "104 ResNet/res2.3/h1_bn/beta:0\n",
      "105 ResNet/res2.3/h1_bn/gamma:0\n",
      "106 ResNet/res2.3/h1_bn/moving_mean:0\n",
      "107 ResNet/res2.3/h1_bn/moving_variance:0\n",
      "108 ResNet/res2.3/h2_conv/filter:0\n",
      "109 ResNet/res2.3/h2_conv/bias:0\n",
      "110 ResNet/res2.4/h0_bn/beta:0\n",
      "111 ResNet/res2.4/h0_bn/gamma:0\n",
      "112 ResNet/res2.4/h0_bn/moving_mean:0\n",
      "113 ResNet/res2.4/h0_bn/moving_variance:0\n",
      "114 ResNet/res2.4/h1_conv/filter:0\n",
      "115 ResNet/res2.4/h1_conv/bias:0\n",
      "116 ResNet/res2.4/h1_bn/beta:0\n",
      "117 ResNet/res2.4/h1_bn/gamma:0\n",
      "118 ResNet/res2.4/h1_bn/moving_mean:0\n",
      "119 ResNet/res2.4/h1_bn/moving_variance:0\n",
      "120 ResNet/res2.4/h2_conv/filter:0\n",
      "121 ResNet/res2.4/h2_conv/bias:0\n",
      "122 ResNet/res3.0/h0_bn/beta:0\n",
      "123 ResNet/res3.0/h0_bn/gamma:0\n",
      "124 ResNet/res3.0/h0_bn/moving_mean:0\n",
      "125 ResNet/res3.0/h0_bn/moving_variance:0\n",
      "126 ResNet/res3.0/h1_conv/filter:0\n",
      "127 ResNet/res3.0/h1_conv/bias:0\n",
      "128 ResNet/res3.0/h1_bn/beta:0\n",
      "129 ResNet/res3.0/h1_bn/gamma:0\n",
      "130 ResNet/res3.0/h1_bn/moving_mean:0\n",
      "131 ResNet/res3.0/h1_bn/moving_variance:0\n",
      "132 ResNet/res3.0/h2_conv/filter:0\n",
      "133 ResNet/res3.0/h2_conv/bias:0\n",
      "134 ResNet/res3.1/h0_bn/beta:0\n",
      "135 ResNet/res3.1/h0_bn/gamma:0\n",
      "136 ResNet/res3.1/h0_bn/moving_mean:0\n",
      "137 ResNet/res3.1/h0_bn/moving_variance:0\n",
      "138 ResNet/res3.1/h1_conv/filter:0\n",
      "139 ResNet/res3.1/h1_conv/bias:0\n",
      "140 ResNet/res3.1/h1_bn/beta:0\n",
      "141 ResNet/res3.1/h1_bn/gamma:0\n",
      "142 ResNet/res3.1/h1_bn/moving_mean:0\n",
      "143 ResNet/res3.1/h1_bn/moving_variance:0\n",
      "144 ResNet/res3.1/h2_conv/filter:0\n",
      "145 ResNet/res3.1/h2_conv/bias:0\n",
      "146 ResNet/res3.2/h0_bn/beta:0\n",
      "147 ResNet/res3.2/h0_bn/gamma:0\n",
      "148 ResNet/res3.2/h0_bn/moving_mean:0\n",
      "149 ResNet/res3.2/h0_bn/moving_variance:0\n",
      "150 ResNet/res3.2/h1_conv/filter:0\n",
      "151 ResNet/res3.2/h1_conv/bias:0\n",
      "152 ResNet/res3.2/h1_bn/beta:0\n",
      "153 ResNet/res3.2/h1_bn/gamma:0\n",
      "154 ResNet/res3.2/h1_bn/moving_mean:0\n",
      "155 ResNet/res3.2/h1_bn/moving_variance:0\n",
      "156 ResNet/res3.2/h2_conv/filter:0\n",
      "157 ResNet/res3.2/h2_conv/bias:0\n",
      "158 ResNet/res3.3/h0_bn/beta:0\n",
      "159 ResNet/res3.3/h0_bn/gamma:0\n",
      "160 ResNet/res3.3/h0_bn/moving_mean:0\n",
      "161 ResNet/res3.3/h0_bn/moving_variance:0\n",
      "162 ResNet/res3.3/h1_conv/filter:0\n",
      "163 ResNet/res3.3/h1_conv/bias:0\n",
      "164 ResNet/res3.3/h1_bn/beta:0\n",
      "165 ResNet/res3.3/h1_bn/gamma:0\n",
      "166 ResNet/res3.3/h1_bn/moving_mean:0\n",
      "167 ResNet/res3.3/h1_bn/moving_variance:0\n",
      "168 ResNet/res3.3/h2_conv/filter:0\n",
      "169 ResNet/res3.3/h2_conv/bias:0\n",
      "170 ResNet/res3.4/h0_bn/beta:0\n",
      "171 ResNet/res3.4/h0_bn/gamma:0\n",
      "172 ResNet/res3.4/h0_bn/moving_mean:0\n",
      "173 ResNet/res3.4/h0_bn/moving_variance:0\n",
      "174 ResNet/res3.4/h1_conv/filter:0\n",
      "175 ResNet/res3.4/h1_conv/bias:0\n",
      "176 ResNet/res3.4/h1_bn/beta:0\n",
      "177 ResNet/res3.4/h1_bn/gamma:0\n",
      "178 ResNet/res3.4/h1_bn/moving_mean:0\n",
      "179 ResNet/res3.4/h1_bn/moving_variance:0\n",
      "180 ResNet/res3.4/h2_conv/filter:0\n",
      "181 ResNet/res3.4/h2_conv/bias:0\n",
      "182 ResNet/r4_bn/beta:0\n",
      "183 ResNet/r4_bn/gamma:0\n",
      "184 ResNet/r4_bn/moving_mean:0\n",
      "185 ResNet/r4_bn/moving_variance:0\n",
      "186 ResNet/fully_connected/weight:0\n",
      "187 ResNet/fully_connected/bias:0\n",
      "188 optimizer/Variable:0\n",
      "189 optimizer/ResNet/r0_conv/filter/Momentum:0\n",
      "190 optimizer/ResNet/r0_conv/bias/Momentum:0\n",
      "191 optimizer/ResNet/r0_bn/beta/Momentum:0\n",
      "192 optimizer/ResNet/r0_bn/gamma/Momentum:0\n",
      "193 optimizer/ResNet/res1.0/h1_conv/filter/Momentum:0\n",
      "194 optimizer/ResNet/res1.0/h1_conv/bias/Momentum:0\n",
      "195 optimizer/ResNet/res1.0/h1_bn/beta/Momentum:0\n",
      "196 optimizer/ResNet/res1.0/h1_bn/gamma/Momentum:0\n",
      "197 optimizer/ResNet/res1.0/h2_conv/filter/Momentum:0\n",
      "198 optimizer/ResNet/res1.0/h2_conv/bias/Momentum:0\n",
      "199 optimizer/ResNet/res1.1/h0_bn/beta/Momentum:0\n",
      "200 optimizer/ResNet/res1.1/h0_bn/gamma/Momentum:0\n",
      "201 optimizer/ResNet/res1.1/h1_conv/filter/Momentum:0\n",
      "202 optimizer/ResNet/res1.1/h1_conv/bias/Momentum:0\n",
      "203 optimizer/ResNet/res1.1/h1_bn/beta/Momentum:0\n",
      "204 optimizer/ResNet/res1.1/h1_bn/gamma/Momentum:0\n",
      "205 optimizer/ResNet/res1.1/h2_conv/filter/Momentum:0\n",
      "206 optimizer/ResNet/res1.1/h2_conv/bias/Momentum:0\n",
      "207 optimizer/ResNet/res1.2/h0_bn/beta/Momentum:0\n",
      "208 optimizer/ResNet/res1.2/h0_bn/gamma/Momentum:0\n",
      "209 optimizer/ResNet/res1.2/h1_conv/filter/Momentum:0\n",
      "210 optimizer/ResNet/res1.2/h1_conv/bias/Momentum:0\n",
      "211 optimizer/ResNet/res1.2/h1_bn/beta/Momentum:0\n",
      "212 optimizer/ResNet/res1.2/h1_bn/gamma/Momentum:0\n",
      "213 optimizer/ResNet/res1.2/h2_conv/filter/Momentum:0\n",
      "214 optimizer/ResNet/res1.2/h2_conv/bias/Momentum:0\n",
      "215 optimizer/ResNet/res1.3/h0_bn/beta/Momentum:0\n",
      "216 optimizer/ResNet/res1.3/h0_bn/gamma/Momentum:0\n",
      "217 optimizer/ResNet/res1.3/h1_conv/filter/Momentum:0\n",
      "218 optimizer/ResNet/res1.3/h1_conv/bias/Momentum:0\n",
      "219 optimizer/ResNet/res1.3/h1_bn/beta/Momentum:0\n",
      "220 optimizer/ResNet/res1.3/h1_bn/gamma/Momentum:0\n",
      "221 optimizer/ResNet/res1.3/h2_conv/filter/Momentum:0\n",
      "222 optimizer/ResNet/res1.3/h2_conv/bias/Momentum:0\n",
      "223 optimizer/ResNet/res1.4/h0_bn/beta/Momentum:0\n",
      "224 optimizer/ResNet/res1.4/h0_bn/gamma/Momentum:0\n",
      "225 optimizer/ResNet/res1.4/h1_conv/filter/Momentum:0\n",
      "226 optimizer/ResNet/res1.4/h1_conv/bias/Momentum:0\n",
      "227 optimizer/ResNet/res1.4/h1_bn/beta/Momentum:0\n",
      "228 optimizer/ResNet/res1.4/h1_bn/gamma/Momentum:0\n",
      "229 optimizer/ResNet/res1.4/h2_conv/filter/Momentum:0\n",
      "230 optimizer/ResNet/res1.4/h2_conv/bias/Momentum:0\n",
      "231 optimizer/ResNet/res2.0/h0_bn/beta/Momentum:0\n",
      "232 optimizer/ResNet/res2.0/h0_bn/gamma/Momentum:0\n",
      "233 optimizer/ResNet/res2.0/h1_conv/filter/Momentum:0\n",
      "234 optimizer/ResNet/res2.0/h1_conv/bias/Momentum:0\n",
      "235 optimizer/ResNet/res2.0/h1_bn/beta/Momentum:0\n",
      "236 optimizer/ResNet/res2.0/h1_bn/gamma/Momentum:0\n",
      "237 optimizer/ResNet/res2.0/h2_conv/filter/Momentum:0\n",
      "238 optimizer/ResNet/res2.0/h2_conv/bias/Momentum:0\n",
      "239 optimizer/ResNet/res2.1/h0_bn/beta/Momentum:0\n",
      "240 optimizer/ResNet/res2.1/h0_bn/gamma/Momentum:0\n",
      "241 optimizer/ResNet/res2.1/h1_conv/filter/Momentum:0\n",
      "242 optimizer/ResNet/res2.1/h1_conv/bias/Momentum:0\n",
      "243 optimizer/ResNet/res2.1/h1_bn/beta/Momentum:0\n",
      "244 optimizer/ResNet/res2.1/h1_bn/gamma/Momentum:0\n",
      "245 optimizer/ResNet/res2.1/h2_conv/filter/Momentum:0\n",
      "246 optimizer/ResNet/res2.1/h2_conv/bias/Momentum:0\n",
      "247 optimizer/ResNet/res2.2/h0_bn/beta/Momentum:0\n",
      "248 optimizer/ResNet/res2.2/h0_bn/gamma/Momentum:0\n",
      "249 optimizer/ResNet/res2.2/h1_conv/filter/Momentum:0\n",
      "250 optimizer/ResNet/res2.2/h1_conv/bias/Momentum:0\n",
      "251 optimizer/ResNet/res2.2/h1_bn/beta/Momentum:0\n",
      "252 optimizer/ResNet/res2.2/h1_bn/gamma/Momentum:0\n",
      "253 optimizer/ResNet/res2.2/h2_conv/filter/Momentum:0\n",
      "254 optimizer/ResNet/res2.2/h2_conv/bias/Momentum:0\n",
      "255 optimizer/ResNet/res2.3/h0_bn/beta/Momentum:0\n",
      "256 optimizer/ResNet/res2.3/h0_bn/gamma/Momentum:0\n",
      "257 optimizer/ResNet/res2.3/h1_conv/filter/Momentum:0\n",
      "258 optimizer/ResNet/res2.3/h1_conv/bias/Momentum:0\n",
      "259 optimizer/ResNet/res2.3/h1_bn/beta/Momentum:0\n",
      "260 optimizer/ResNet/res2.3/h1_bn/gamma/Momentum:0\n",
      "261 optimizer/ResNet/res2.3/h2_conv/filter/Momentum:0\n",
      "262 optimizer/ResNet/res2.3/h2_conv/bias/Momentum:0\n",
      "263 optimizer/ResNet/res2.4/h0_bn/beta/Momentum:0\n",
      "264 optimizer/ResNet/res2.4/h0_bn/gamma/Momentum:0\n",
      "265 optimizer/ResNet/res2.4/h1_conv/filter/Momentum:0\n",
      "266 optimizer/ResNet/res2.4/h1_conv/bias/Momentum:0\n",
      "267 optimizer/ResNet/res2.4/h1_bn/beta/Momentum:0\n",
      "268 optimizer/ResNet/res2.4/h1_bn/gamma/Momentum:0\n",
      "269 optimizer/ResNet/res2.4/h2_conv/filter/Momentum:0\n",
      "270 optimizer/ResNet/res2.4/h2_conv/bias/Momentum:0\n",
      "271 optimizer/ResNet/res3.0/h0_bn/beta/Momentum:0\n",
      "272 optimizer/ResNet/res3.0/h0_bn/gamma/Momentum:0\n",
      "273 optimizer/ResNet/res3.0/h1_conv/filter/Momentum:0\n",
      "274 optimizer/ResNet/res3.0/h1_conv/bias/Momentum:0\n",
      "275 optimizer/ResNet/res3.0/h1_bn/beta/Momentum:0\n",
      "276 optimizer/ResNet/res3.0/h1_bn/gamma/Momentum:0\n",
      "277 optimizer/ResNet/res3.0/h2_conv/filter/Momentum:0\n",
      "278 optimizer/ResNet/res3.0/h2_conv/bias/Momentum:0\n",
      "279 optimizer/ResNet/res3.1/h0_bn/beta/Momentum:0\n",
      "280 optimizer/ResNet/res3.1/h0_bn/gamma/Momentum:0\n",
      "281 optimizer/ResNet/res3.1/h1_conv/filter/Momentum:0\n",
      "282 optimizer/ResNet/res3.1/h1_conv/bias/Momentum:0\n",
      "283 optimizer/ResNet/res3.1/h1_bn/beta/Momentum:0\n",
      "284 optimizer/ResNet/res3.1/h1_bn/gamma/Momentum:0\n",
      "285 optimizer/ResNet/res3.1/h2_conv/filter/Momentum:0\n",
      "286 optimizer/ResNet/res3.1/h2_conv/bias/Momentum:0\n",
      "287 optimizer/ResNet/res3.2/h0_bn/beta/Momentum:0\n",
      "288 optimizer/ResNet/res3.2/h0_bn/gamma/Momentum:0\n",
      "289 optimizer/ResNet/res3.2/h1_conv/filter/Momentum:0\n",
      "290 optimizer/ResNet/res3.2/h1_conv/bias/Momentum:0\n",
      "291 optimizer/ResNet/res3.2/h1_bn/beta/Momentum:0\n",
      "292 optimizer/ResNet/res3.2/h1_bn/gamma/Momentum:0\n",
      "293 optimizer/ResNet/res3.2/h2_conv/filter/Momentum:0\n",
      "294 optimizer/ResNet/res3.2/h2_conv/bias/Momentum:0\n",
      "295 optimizer/ResNet/res3.3/h0_bn/beta/Momentum:0\n",
      "296 optimizer/ResNet/res3.3/h0_bn/gamma/Momentum:0\n",
      "297 optimizer/ResNet/res3.3/h1_conv/filter/Momentum:0\n",
      "298 optimizer/ResNet/res3.3/h1_conv/bias/Momentum:0\n",
      "299 optimizer/ResNet/res3.3/h1_bn/beta/Momentum:0\n",
      "300 optimizer/ResNet/res3.3/h1_bn/gamma/Momentum:0\n",
      "301 optimizer/ResNet/res3.3/h2_conv/filter/Momentum:0\n",
      "302 optimizer/ResNet/res3.3/h2_conv/bias/Momentum:0\n",
      "303 optimizer/ResNet/res3.4/h0_bn/beta/Momentum:0\n",
      "304 optimizer/ResNet/res3.4/h0_bn/gamma/Momentum:0\n",
      "305 optimizer/ResNet/res3.4/h1_conv/filter/Momentum:0\n",
      "306 optimizer/ResNet/res3.4/h1_conv/bias/Momentum:0\n",
      "307 optimizer/ResNet/res3.4/h1_bn/beta/Momentum:0\n",
      "308 optimizer/ResNet/res3.4/h1_bn/gamma/Momentum:0\n",
      "309 optimizer/ResNet/res3.4/h2_conv/filter/Momentum:0\n",
      "310 optimizer/ResNet/res3.4/h2_conv/bias/Momentum:0\n",
      "311 optimizer/ResNet/r4_bn/beta/Momentum:0\n",
      "312 optimizer/ResNet/r4_bn/gamma/Momentum:0\n",
      "313 optimizer/ResNet/fully_connected/weight/Momentum:0\n",
      "314 optimizer/ResNet/fully_connected/bias/Momentum:0\n",
      "Training stage 3: Epoch training...\n",
      "Training epoch 0, iteration 0, global_step 0, batch_loss 2.30017066002, batch_accuracy 0.119999997318\n",
      "Training epoch 0, iteration 50, global_step 50, batch_loss 0.31825158, batch_accuracy 0.960000038147\n",
      "Training epoch 0, iteration 100, global_step 100, batch_loss 0.292034059763, batch_accuracy 0.930000007153\n",
      "Training epoch 0, iteration 150, global_step 150, batch_loss 0.225130409002, batch_accuracy 0.939999997616\n",
      "Training epoch 0, iteration 200, global_step 200, batch_loss 0.0737120360136, batch_accuracy 1.0\n",
      "Training epoch 0, iteration 250, global_step 250, batch_loss 0.0889566093683, batch_accuracy 0.97000002861\n",
      "Training epoch 0, iteration 300, global_step 300, batch_loss 0.0804965570569, batch_accuracy 0.990000009537\n",
      "Training epoch 0, iteration 350, global_step 350, batch_loss 0.0461337007582, batch_accuracy 1.0\n",
      "Training epoch 0, iteration 400, global_step 400, batch_loss 0.053699132055, batch_accuracy 1.0\n",
      "Training epoch 0, iteration 450, global_step 450, batch_loss 0.120877310634, batch_accuracy 0.980000019073\n",
      "Training epoch 0, iteration 500, global_step 500, batch_loss 0.067562751472, batch_accuracy 0.989999949932\n",
      "Training epoch 0, iteration 550, global_step 550, batch_loss 0.062621511519, batch_accuracy 0.990000009537\n",
      "Testing epoch 0, loss 0.075502054058, error 0.0130999904871\n",
      "Training epoch 1, iteration 0, global_step 600, batch_loss 0.0539277866483, batch_accuracy 1.0\n",
      "Training epoch 1, iteration 50, global_step 650, batch_loss 0.0452932454646, batch_accuracy 1.0\n",
      "Training epoch 1, iteration 100, global_step 700, batch_loss 0.0748582333326, batch_accuracy 0.980000019073\n",
      "Training epoch 1, iteration 150, global_step 750, batch_loss 0.0679623559117, batch_accuracy 0.980000019073\n",
      "Training epoch 1, iteration 200, global_step 800, batch_loss 0.0689531341195, batch_accuracy 0.990000009537\n",
      "Training epoch 1, iteration 250, global_step 850, batch_loss 0.038726542145, batch_accuracy 1.0"
     ]
    }
   ],
   "source": [
    "config = tf.ConfigProto(allow_soft_placement = True)\n",
    "config.gpu_options.allow_growth = True\n",
    "# Create computation graph.\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    # Set GPU number and train.\n",
    "    gpu_number = 0\n",
    "    with tf.device(\"/gpu:{0}\".format(gpu_number)):    \n",
    "        # Training session.\n",
    "        with tf.Session(config = config) as sess:\n",
    "            train(sess)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
